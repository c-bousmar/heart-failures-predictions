{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data_students/labeled_data/X_train.csv')\n",
    "X_test = pd.read_csv('../data_students/labeled_data/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images cropped successfully!\n"
     ]
    }
   ],
   "source": [
    "def remove_image_borders(input_folder, output_folder, border_size=5):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(('.png')):\n",
    "            img_path = os.path.join(input_folder, filename)\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            width, height = img.size\n",
    "            \n",
    "            cropped_img = img.crop((\n",
    "                border_size,  # Left\n",
    "                border_size,  # Top\n",
    "                width - border_size,  # Right\n",
    "                height - border_size  # Bottom\n",
    "            ))\n",
    "            cropped_img.save(os.path.join(output_folder, filename))\n",
    "\n",
    "img_folder = {\n",
    "    'Img_train': '../data_students/labeled_data/Img_train',\n",
    "    'Img_test': '../data_students/labeled_data/Img_test',\n",
    "}\n",
    "\n",
    "img_cropped_folder = {\n",
    "    'Img_train_cropped': '../data_students/labeled_data/Img_train_cropped',\n",
    "    'Img_test_cropped': '../data_students/labeled_data/Img_test_cropped',\n",
    "}\n",
    "\n",
    "for folder, input_path in img_folder.items():\n",
    "    output_path = img_cropped_folder[folder + '_cropped']\n",
    "    remove_image_borders(input_path, output_path)\n",
    "print(\"All images cropped successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_images_to_set(input_folder):\n",
    "    flattened_images_set = set()\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(('.png')):\n",
    "            img_path = os.path.join(input_folder, filename)\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            img_gray = img.convert('L')  # Convert to grayscale\n",
    "            img_array = np.array(img_gray).flatten()\n",
    "            flattened_images_set.add((filename, tuple(img_array)))\n",
    "    return flattened_images_set\n",
    "\n",
    "train_images_set = flatten_images_to_set(img_cropped_folder['Img_train_cropped'])\n",
    "test_images_set = flatten_images_to_set(img_cropped_folder['Img_test_cropped'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_flattened_images_to_dataframe(df, flattened_images_set, img_filename_col='img_filename'):\n",
    "    flattened_images_dict = {name: values for name, values in flattened_images_set}\n",
    "\n",
    "    if len(flattened_images_set) > 0:\n",
    "        num_pixels = len(next(iter(flattened_images_dict.values())))\n",
    "        new_cols = [f\"pixel_{i + 1}\" for i in range(num_pixels)]\n",
    "    else:\n",
    "        raise ValueError(\"Flattened images set is empty.\")\n",
    "\n",
    "    pixel_data = df[img_filename_col].map(flattened_images_dict)\n",
    "    if pixel_data.isna().any():\n",
    "        raise ValueError(\"Some filenames in the DataFrame do not match those in the image set.\")\n",
    "\n",
    "    pixel_df = pd.DataFrame(pixel_data.tolist(), columns=new_cols, index=df.index)\n",
    "\n",
    "    updated_df = pd.concat([df.drop(columns=[img_filename_col]), pixel_df], axis=1)\n",
    "\n",
    "    return updated_df\n",
    "\n",
    "X_train = add_flattened_images_to_dataframe(X_train, train_images_set)\n",
    "X_test = add_flattened_images_to_dataframe(X_test, test_images_set)\n",
    "\n",
    "X_train.to_csv('../data_students/labeled_data/X_train_with_images.csv', index=False)\n",
    "X_test.to_csv('../data_students/labeled_data/X_test_with_images.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data_students/labeled_data/X_train_combined.csv')\n",
    "X_test = pd.read_csv('../data_students/labeled_data/X_test_combined.csv')\n",
    "y_train = pd.read_csv('../data_students/labeled_data/y_train.csv', header=None).squeeze()\n",
    "y_test = pd.read_csv('../data_students/labeled_data/y_test.csv', header=None).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = LabelEncoder()\n",
    "X_train['profession'] = label_encoders.fit_transform(X_train['profession'])\n",
    "X_test['profession'] = label_encoders.transform(X_test['profession'])\n",
    "\n",
    "categorical_columns = X_train.select_dtypes(include=['object']).columns\n",
    "satisfaction_order = ['Very low', 'Low', 'Moderate', 'High', 'Very high']\n",
    "ordinal_encoders = OrdinalEncoder(categories=[satisfaction_order])\n",
    "for column in categorical_columns:\n",
    "    X_train[column] = ordinal_encoders.fit_transform(X_train[column].values.reshape(-1, 1))\n",
    "    X_test[column] = ordinal_encoders.transform(X_test[column].values.reshape(-1, 1))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_cols = [col for col in X_train.columns if col.startswith(\"pixel_\")]\n",
    "tabular_cols = [col for col in X_train.columns if col not in pixel_cols]\n",
    "\n",
    "X_train_tabular = X_train[tabular_cols].copy()\n",
    "X_train_pixels = X_train[pixel_cols].copy()\n",
    "\n",
    "X_test_tabular = X_test[tabular_cols].copy()\n",
    "X_test_pixels = X_test[pixel_cols].copy()\n",
    "\n",
    "X_train_tabular = X_train_tabular.drop(columns=['profession', 'hemoglobin', 'calcium', 'vitamin D'])\n",
    "X_test_tabular = X_test_tabular.drop(columns=['profession', 'hemoglobin', 'calcium', 'vitamin D'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blood pressure',\n",
       " 'weight',\n",
       " 'sarsaparilla',\n",
       " 'cholesterol',\n",
       " 'smurfin donuts',\n",
       " 'age',\n",
       " 'height',\n",
       " 'potassium',\n",
       " '179',\n",
       " 'smurfberry liquor',\n",
       " '246',\n",
       " '247',\n",
       " '221',\n",
       " '197',\n",
       " '63',\n",
       " '265',\n",
       " '169',\n",
       " '92',\n",
       " '119',\n",
       " '94']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corr(X_train, y_train, k):\n",
    "    y_train = y_train.squeeze()\n",
    "    X_train_copy = X_train.copy()\n",
    "    X_train_copy['target'] = y_train\n",
    "    corr = X_train_copy.corr(method='pearson')['target'].drop('target')\n",
    "    abs_corr = corr.abs().sort_values(ascending=False)\n",
    "    top_features = abs_corr.head(k).index.tolist()\n",
    "    return top_features\n",
    "\n",
    "corr(X_train, y_train, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection and Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "\n",
      "RMSE= 0.0720, STD= 0.0707\n",
      "Best Parameters: p=2.0, C=0.5, epsilon=0.01\n"
     ]
    }
   ],
   "source": [
    "model = SVR(kernel='rbf')\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "    'epsilon': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "    'p': [2, 4, 8, 16, 32, 64, 128]\n",
    "}\n",
    "\n",
    "results = []\n",
    "for p in param_grid['p']:\n",
    "    top_pixel_features = corr(X_train_pixels, y_train, p)\n",
    "    X_train_selected = np.hstack([X_train_tabular, X_train_pixels[top_pixel_features]])\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(X_train_selected, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    svr_param_grid = {\n",
    "        'C': param_grid['C'],\n",
    "        'epsilon': param_grid['epsilon']\n",
    "    }\n",
    "    grid_search = GridSearchCV(model, svr_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X_train_split, y_train_split)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    rmse_val = root_mean_squared_error(y_val, y_val_pred)\n",
    "    std_val = np.std(y_val - y_val_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'p': p,\n",
    "        'C': best_params['C'],\n",
    "        'epsilon': best_params['epsilon'],\n",
    "        'validation_rmse': rmse_val,\n",
    "        'validation_std': std_val\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "best_result = results_df.loc[results_df['validation_rmse'].idxmin()]\n",
    "best_p = best_result['p']\n",
    "best_C = best_result['C']\n",
    "best_epsilon = best_result['epsilon']\n",
    "print(f\"\\nRMSE= {best_result['validation_rmse']:.4f}, STD= {best_result['validation_std']:.4f}\")\n",
    "print(f\"Best Parameters: p={best_p}, C={best_C}, epsilon={best_epsilon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.0860\n"
     ]
    }
   ],
   "source": [
    "top_pixel_features = corr(X_train_pixels, y_train, int(best_result['p']))\n",
    "\n",
    "X_train_final = np.hstack([X_train_tabular, X_train_pixels[top_pixel_features]])\n",
    "X_test_final = np.hstack([X_test_tabular, X_test_pixels[top_pixel_features]])\n",
    "\n",
    "final_model = SVR(kernel='rbf', C=best_C, epsilon=best_epsilon)\n",
    "final_model.fit(X_train_final, y_train)\n",
    "\n",
    "y_test_pred = final_model.predict(X_test_final)\n",
    "test_rmse = root_mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (18,18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(example_image_indices):\n\u001b[1;32m     19\u001b[0m     example_image_flattened \u001b[38;5;241m=\u001b[39m X_test_pixels\u001b[38;5;241m.\u001b[39miloc[idx]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m---> 20\u001b[0m     highlighted_image \u001b[38;5;241m=\u001b[39m \u001b[43mhighlight_pixels_with_overlay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_image_flattened\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_pixel_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     ax \u001b[38;5;241m=\u001b[39m axes[i]\n\u001b[1;32m     23\u001b[0m     ax\u001b[38;5;241m.\u001b[39mimshow(highlighted_image, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m, in \u001b[0;36mhighlight_pixels_with_overlay\u001b[0;34m(image, selected_pixel_indices, img_shape)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhighlight_pixels_with_overlay\u001b[39m(image, selected_pixel_indices, img_shape):\n\u001b[0;32m----> 2\u001b[0m     highlighted_image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      3\u001b[0m     max_value \u001b[38;5;241m=\u001b[39m highlighted_image\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m selected_pixel_indices:\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (18,18)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def highlight_pixels_with_overlay(image, selected_pixel_indices, img_shape):\n",
    "    highlighted_image = image.reshape(img_shape).copy()\n",
    "    max_value = highlighted_image.max()\n",
    "\n",
    "    for idx in selected_pixel_indices:\n",
    "        highlighted_image[idx // img_shape[1], idx % img_shape[1]] = max_value\n",
    "    \n",
    "    return highlighted_image\n",
    "\n",
    "example_image_indices = [0, 1, 2, 3, 4]\n",
    "\n",
    "selected_pixel_indices = [X_train_pixels.columns.get_loc(feature) for feature in top_pixel_features]\n",
    "\n",
    "img_shape = (18, 18)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(12, 6))\n",
    "\n",
    "for i, idx in enumerate(example_image_indices):\n",
    "    example_image_flattened = X_test_pixels.iloc[idx].to_numpy()\n",
    "    highlighted_image = highlight_pixels_with_overlay(example_image_flattened, selected_pixel_indices, img_shape)\n",
    "    \n",
    "    ax = axes[i]\n",
    "    ax.imshow(highlighted_image, cmap='gray')\n",
    "    ax.set_title(f\"Image {idx} - Highlighted\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
