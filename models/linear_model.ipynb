{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A better linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_regression, SequentialFeatureSelector, RFECV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, PoissonRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../data_students/labeled_data/X_train.csv')\n",
    "X_test  = pd.read_csv('../data_students/labeled_data/X_test.csv')\n",
    "y = pd.read_csv('../data_students/labeled_data/y_train.csv', header=None)\n",
    "y_test  = pd.read_csv('../data_students/labeled_data/y_test.csv', header=None)\n",
    "\n",
    "# Getting rid of the column 'img_filename'\n",
    "X = X.drop(columns=['img_filename'])\n",
    "X_test  = X_test.drop(columns=['img_filename'])\n",
    "\n",
    "y      = y.squeeze()\n",
    "y_test = y_test.squeeze()\n",
    "\n",
    "profession_categories = [['food production', 'administration and governance', 'services', 'ressource extraction', 'craftsmanship', 'manufacturing']]\n",
    "ordinal_categories = ['sarsaparilla', 'smurfberry liquor', 'smurfin donuts']\n",
    "normally_distributed_categories = ['age', 'blood pressure', 'calcium', 'cholesterol', 'hemoglobin', 'height', 'potassium', 'vitamin D', 'weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers handling**\n",
    "\n",
    "Cholesterol has really bad outliers, so we remove them and it improves the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholesterol_indexes = X[X['cholesterol'] < 5].index\n",
    "X = X.drop(cholesterol_indexes).reset_index(drop=True)\n",
    "y = y.drop(cholesterol_indexes).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ordinal encoding**\n",
    "\n",
    "Since sarsaparilla, smurfberry liquor and smurfin donuts have some ordinality (from very low to very high) we can transform it with values from 0 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder(categories=[['Very low', 'Low', 'Moderate', 'High', 'Very high']])\n",
    "for category in ordinal_categories:\n",
    "    X[category]      = ordinal_encoder.fit_transform(X[[category]])\n",
    "    X_test[category] = ordinal_encoder.transform(X_test[[category]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-hot encoder** for Profession category\n",
    "\n",
    "We create a vector of values which are set to zeros except for the profession value of the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder(categories=profession_categories, sparse_output=False)\n",
    "\n",
    "profession_encoded_train = one_hot_encoder.fit_transform(X[['profession']])\n",
    "profession_encoded_train_df = pd.DataFrame(profession_encoded_train, columns=one_hot_encoder.get_feature_names_out(['profession']))\n",
    "X = pd.concat([X.drop('profession', axis=1), profession_encoded_train_df], axis=1)\n",
    "\n",
    "profession_encoded_test = one_hot_encoder.transform(X_test[['profession']])\n",
    "profession_encoded_test_df = pd.DataFrame(profession_encoded_test, columns=one_hot_encoder.get_feature_names_out(['profession']))\n",
    "X_test = pd.concat([X_test.drop('profession', axis=1), profession_encoded_test_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization\n",
    "We should check for the MinMaxScaler because there is no improvement compare to StandardScaler for the ordinal_categories.\n",
    "\n",
    "Output is not scaled since it is already $\\in [0, 1]$, being a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_scaler = MinMaxScaler()\n",
    "X[ordinal_categories] = pd.DataFrame(ordinal_scaler.fit_transform(X[ordinal_categories]))\n",
    "X_test[ordinal_categories] = pd.DataFrame(ordinal_scaler.transform(X_test[ordinal_categories]))\n",
    "\n",
    "normal_scaler = RobustScaler()\n",
    "X[normally_distributed_categories] = pd.DataFrame(normal_scaler.fit_transform(X[normally_distributed_categories]))\n",
    "X_test[normally_distributed_categories] = pd.DataFrame(normal_scaler.transform(X_test[normally_distributed_categories]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_performance(y_pred, features):\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Selected features: \")\n",
    "    for feature in features:\n",
    "        print(f\"- {feature}\")\n",
    "    print(\"----------------------------------\")\n",
    "    print(f\"RMSE: \\t\\t\\t{rmse:.6f}\")\n",
    "    print(f\"Mean Absolute Error: \\t{mae:.6f}\")\n",
    "    print(f\"R-squared score: \\t{r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "- age\n",
      "- blood pressure\n",
      "- calcium\n",
      "- cholesterol\n",
      "- hemoglobin\n",
      "- height\n",
      "- potassium\n",
      "- sarsaparilla\n",
      "- smurfberry liquor\n",
      "- smurfin donuts\n",
      "- vitamin D\n",
      "- weight\n",
      "- profession_food production\n",
      "- profession_administration and governance\n",
      "- profession_services\n",
      "- profession_ressource extraction\n",
      "- profession_craftsmanship\n",
      "- profession_manufacturing\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077627\n",
      "Mean Absolute Error: \t0.056825\n",
      "R-squared score: \t0.311337\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression().fit(X[X.columns], y)\n",
    "y_pred = model.predict(X_test[X.columns])\n",
    "selection_performance(y_pred, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests for selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation filter** determines that using the eleventh most correlated features to the output gives us the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "- profession_services\n",
      "- profession_administration and governance\n",
      "- smurfberry liquor\n",
      "- potassium\n",
      "- height\n",
      "- age\n",
      "- smurfin donuts\n",
      "- cholesterol\n",
      "- sarsaparilla\n",
      "- weight\n",
      "- blood pressure\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077385\n",
      "Mean Absolute Error: \t0.056731\n",
      "R-squared score: \t0.315622\n"
     ]
    }
   ],
   "source": [
    "n_features = 11\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "correlation_filter_scores = np.zeros(X.shape[1])\n",
    "for train_idx, val_idx in rkf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    corr = X_train.corrwith(y_train).abs()\n",
    "    correlation_filter_scores += corr\n",
    "correlation_filter_scores /= (rkf.get_n_splits())\n",
    "top_features_indices = np.argsort(correlation_filter_scores)[-n_features:]\n",
    "best_features_corr = X.columns[top_features_indices]\n",
    "\n",
    "y_pred = LinearRegression().fit(X[best_features_corr], y).predict(X_test[best_features_corr])\n",
    "selection_performance(y_pred, best_features_corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutual information filtering** gives us little information. 16 features are required, only removing ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "- profession_administration and governance\n",
      "- height\n",
      "- profession_food production\n",
      "- profession_manufacturing\n",
      "- smurfin donuts\n",
      "- profession_ressource extraction\n",
      "- smurfberry liquor\n",
      "- profession_services\n",
      "- hemoglobin\n",
      "- cholesterol\n",
      "- age\n",
      "- sarsaparilla\n",
      "- potassium\n",
      "- calcium\n",
      "- weight\n",
      "- blood pressure\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077626\n",
      "Mean Absolute Error: \t0.056826\n",
      "R-squared score: \t0.311351\n"
     ]
    }
   ],
   "source": [
    "n_features = 16\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "mutual_info_scores = np.zeros(X.shape[1])\n",
    "for train_idx, val_idx in rkf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    mi = mutual_info_regression(X_train, y_train, random_state=42)\n",
    "    mutual_info_scores += mi\n",
    "mutual_info_scores /= (rkf.get_n_splits())\n",
    "top_features_indices = np.argsort(mutual_info_scores)[-n_features:]\n",
    "best_features = X.columns[top_features_indices]\n",
    "\n",
    "y_pred = LinearRegression().fit(X[best_features], y).predict(X_test[best_features])\n",
    "selection_performance(y_pred, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maximum relevance and minimum redundancy** is basically just removing smurfin donuts and keeping weight or conversely, as those are the only features really correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "- blood pressure\n",
      "- weight\n",
      "- calcium\n",
      "- potassium\n",
      "- sarsaparilla\n",
      "- age\n",
      "- cholesterol\n",
      "- hemoglobin\n",
      "- profession_services\n",
      "- smurfberry liquor\n",
      "- profession_ressource extraction\n",
      "- profession_manufacturing\n",
      "- profession_food production\n",
      "- height\n",
      "- profession_administration and governance\n",
      "- vitamin D\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077655\n",
      "Mean Absolute Error: \t0.056826\n",
      "R-squared score: \t0.310824\n"
     ]
    }
   ],
   "source": [
    "n_features = 16\n",
    "corr_threshold = 0.6\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "mutual_info_scores = np.zeros(X.shape[1])\n",
    "for train_idx, val_idx in rkf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    mi = mutual_info_regression(X_train, y_train, random_state=42)\n",
    "    mutual_info_scores += mi\n",
    "mutual_info_scores /= (rkf.get_n_splits())\n",
    "\n",
    "mi_series = pd.Series(mutual_info_scores, index=X.columns)\n",
    "ranked_features = list(mi_series.sort_values(ascending=False).index)\n",
    "\n",
    "corr = X.corr()\n",
    "\n",
    "selected_features = []\n",
    "for feature in ranked_features:\n",
    "    if len(selected_features) == n_features:\n",
    "        break\n",
    "    elif len(selected_features) == 0:\n",
    "        selected_features.append(feature)\n",
    "    else:\n",
    "        feature_is_redundant = False\n",
    "        for selected_feature in selected_features:\n",
    "            if np.abs(corr[feature][selected_feature]) > corr_threshold:\n",
    "                feature_is_redundant = True\n",
    "                break\n",
    "        if not feature_is_redundant:\n",
    "            selected_features.append(feature)\n",
    "\n",
    "best_features = selected_features\n",
    "\n",
    "y_pred = LinearRegression().fit(X[best_features], y).predict(X_test[best_features])\n",
    "selection_performance(y_pred, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward wrapper** gives no concluant result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "- age\n",
      "- blood pressure\n",
      "- cholesterol\n",
      "- height\n",
      "- potassium\n",
      "- sarsaparilla\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "- profession_ressource extraction\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077596\n",
      "Mean Absolute Error: \t0.057068\n",
      "R-squared score: \t0.311880\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "sfs = SequentialFeatureSelector(LinearRegression(), n_features_to_select='auto', direction='forward', cv=rkf)\n",
    "sfs.fit(X, y)\n",
    "best_features = X.columns[sfs.support_]\n",
    "\n",
    "y_pred = LinearRegression().fit(X[best_features],y).predict(X_test[best_features])\n",
    "selection_performance(y_pred, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backward wrapper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "- age\n",
      "- blood pressure\n",
      "- cholesterol\n",
      "- height\n",
      "- potassium\n",
      "- sarsaparilla\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "- profession_ressource extraction\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077596\n",
      "Mean Absolute Error: \t0.057068\n",
      "R-squared score: \t0.311880\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "sfs = SequentialFeatureSelector(LinearRegression(), n_features_to_select='auto', direction='backward', cv=rkf)\n",
    "sfs.fit(X, y)\n",
    "best_features = X.columns[sfs.support_]\n",
    "\n",
    "y_pred = LinearRegression().fit(X[best_features],y).predict(X_test[best_features])\n",
    "selection_performance(y_pred, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree** For most relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "- age                  0.098\n",
      "- blood pressure       0.490\n",
      "- calcium              0.021\n",
      "- cholesterol          0.059\n",
      "- hemoglobin           0.034\n",
      "- height               0.024\n",
      "- potassium            0.122\n",
      "- sarsaparilla         0.025\n",
      "- smurfberry liquor    0.057\n",
      "- smurfin donuts       0.011\n",
      "- vitamin D            0.002\n",
      "- weight               0.042\n",
      "- profession_food production 0.000\n",
      "- profession_administration and governance 0.000\n",
      "- profession_services  0.016\n",
      "- profession_ressource extraction 0.000\n",
      "- profession_craftsmanship 0.000\n",
      "- profession_manufacturing 0.000\n",
      "--------------------------------------\n",
      "Decision tree RMSE: 0.083\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=7) # best depth, tried different ones.\n",
    "dt.fit(X, y)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "rmse = np.sqrt(np.mean((y_pred-y_test.values.ravel())**2))\n",
    "\n",
    "feature_importances = pd.Series(dt.feature_importances_, index=X.columns)\n",
    "\n",
    "print(\"Feature importances:\")\n",
    "for feature,feature_importance in feature_importances.items():\n",
    "    print(f\"- {feature:20} {feature_importance:5.3f}\")\n",
    "print(\"--------------------------------------\")\n",
    "print(f\"Decision tree RMSE: {rmse:5.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.082283\n",
      "Mean Absolute Error: \t0.059738\n",
      "R-squared score: \t0.226233\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.082290\n",
      "Mean Absolute Error: \t0.059751\n",
      "R-squared score: \t0.226106\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.082012\n",
      "Mean Absolute Error: \t0.059687\n",
      "R-squared score: \t0.231326\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "- smurfberry liquor\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.081036\n",
      "Mean Absolute Error: \t0.059167\n",
      "R-squared score: \t0.249516\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.078908\n",
      "Mean Absolute Error: \t0.057616\n",
      "R-squared score: \t0.288418\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "- hemoglobin\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.078866\n",
      "Mean Absolute Error: \t0.057467\n",
      "R-squared score: \t0.289177\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "- hemoglobin\n",
      "- sarsaparilla\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.078540\n",
      "Mean Absolute Error: \t0.057430\n",
      "R-squared score: \t0.295033\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "- hemoglobin\n",
      "- sarsaparilla\n",
      "- height\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077466\n",
      "Mean Absolute Error: \t0.056774\n",
      "R-squared score: \t0.314188\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "- hemoglobin\n",
      "- sarsaparilla\n",
      "- height\n",
      "- calcium\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077523\n",
      "Mean Absolute Error: \t0.056754\n",
      "R-squared score: \t0.313175\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "- hemoglobin\n",
      "- sarsaparilla\n",
      "- height\n",
      "- calcium\n",
      "- profession_services\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077508\n",
      "Mean Absolute Error: \t0.056753\n",
      "R-squared score: \t0.313445\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "- hemoglobin\n",
      "- sarsaparilla\n",
      "- height\n",
      "- calcium\n",
      "- profession_services\n",
      "- smurfin donuts\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077452\n",
      "Mean Absolute Error: \t0.056799\n",
      "R-squared score: \t0.314423\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "- hemoglobin\n",
      "- sarsaparilla\n",
      "- height\n",
      "- calcium\n",
      "- profession_services\n",
      "- smurfin donuts\n",
      "- vitamin D\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077453\n",
      "Mean Absolute Error: \t0.056798\n",
      "R-squared score: \t0.314419\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "- hemoglobin\n",
      "- sarsaparilla\n",
      "- height\n",
      "- calcium\n",
      "- profession_services\n",
      "- smurfin donuts\n",
      "- vitamin D\n",
      "- profession_food production\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077584\n",
      "Mean Absolute Error: \t0.056915\n",
      "R-squared score: \t0.312097\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "- hemoglobin\n",
      "- sarsaparilla\n",
      "- height\n",
      "- calcium\n",
      "- profession_services\n",
      "- smurfin donuts\n",
      "- vitamin D\n",
      "- profession_food production\n",
      "- profession_administration and governance\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077556\n",
      "Mean Absolute Error: \t0.056777\n",
      "R-squared score: \t0.312586\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "- hemoglobin\n",
      "- sarsaparilla\n",
      "- height\n",
      "- calcium\n",
      "- profession_services\n",
      "- smurfin donuts\n",
      "- vitamin D\n",
      "- profession_food production\n",
      "- profession_administration and governance\n",
      "- profession_ressource extraction\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077580\n",
      "Mean Absolute Error: \t0.056869\n",
      "R-squared score: \t0.312155\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "- hemoglobin\n",
      "- sarsaparilla\n",
      "- height\n",
      "- calcium\n",
      "- profession_services\n",
      "- smurfin donuts\n",
      "- vitamin D\n",
      "- profession_food production\n",
      "- profession_administration and governance\n",
      "- profession_ressource extraction\n",
      "- profession_craftsmanship\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077627\n",
      "Mean Absolute Error: \t0.056825\n",
      "R-squared score: \t0.311337\n",
      "\n",
      "Selected features: \n",
      "- blood pressure\n",
      "- potassium\n",
      "- age\n",
      "- cholesterol\n",
      "- smurfberry liquor\n",
      "- weight\n",
      "- hemoglobin\n",
      "- sarsaparilla\n",
      "- height\n",
      "- calcium\n",
      "- profession_services\n",
      "- smurfin donuts\n",
      "- vitamin D\n",
      "- profession_food production\n",
      "- profession_administration and governance\n",
      "- profession_ressource extraction\n",
      "- profession_craftsmanship\n",
      "- profession_manufacturing\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.078002\n",
      "Mean Absolute Error: \t0.057322\n",
      "R-squared score: \t0.304659\n",
      "\n",
      "Best number of features: 12\n"
     ]
    }
   ],
   "source": [
    "n_features = 18\n",
    "n_best = 2\n",
    "rmse_best = np.inf\n",
    "for i in range (2, n_features+1):\n",
    "    best_features = list(feature_importances.sort_values(ascending=False)[:i].index)\n",
    "    y_pred = LinearRegression().fit(X[best_features],y).predict(X_test[best_features])\n",
    "    #print(f\"Number of features: {i}\")\n",
    "    selection_performance(y_pred, best_features)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    if rmse < rmse_best:\n",
    "        rmse_best = rmse\n",
    "        n_best = i\n",
    "    print()\n",
    "\n",
    "print(f\"Best number of features: {n_best}\")\n",
    "    \n",
    "\n",
    "# best_features = list(feature_importances.sort_values(ascending=False)[:n_features].index)\n",
    "# y_pred = LinearRegression().fit(X[best_features],y).predict(X_test[best_features])\n",
    "# selection_performance(y_pred, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursive feature elimination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n",
      "- age\n",
      "- blood pressure\n",
      "- cholesterol\n",
      "- height\n",
      "- potassium\n",
      "- sarsaparilla\n",
      "- smurfberry liquor\n",
      "- smurfin donuts\n",
      "- weight\n",
      "- profession_ressource extraction\n",
      "- profession_manufacturing\n",
      "----------------------------------\n",
      "RMSE: \t\t\t0.077594\n",
      "Mean Absolute Error: \t0.056910\n",
      "R-squared score: \t0.311906\n"
     ]
    }
   ],
   "source": [
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "rfecv = RFECV(estimator=LinearRegression(), step=1, cv=rkf, scoring='neg_mean_squared_error')\n",
    "rfecv.fit(X, y)\n",
    "best_features = X.columns[rfecv.support_]\n",
    "\n",
    "y_pred = rfecv.predict(X_test)\n",
    "selection_performance(y_pred, best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update training data and test data \n",
    "X = X[best_features_corr]\n",
    "X_test = X_test[best_features_corr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_learn, X_val, y_learn, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearRegression(), Mean RMSE across 5 folds: 0.07806606174131595\n",
      "Model: Lasso(), Mean RMSE across 5 folds: 0.08896551947291972\n",
      "Model: Ridge(), Mean RMSE across 5 folds: 0.07804962640804718\n",
      "Model: ElasticNet(), Mean RMSE across 5 folds: 0.08896551947291972\n",
      "Model: PoissonRegressor(), Mean RMSE across 5 folds: 0.08772361102298927\n",
      "\n",
      "Best model: Ridge()\n",
      "RMSE on the test set: 0.077057\n",
      "Mean Absolute Error on the test set: 0.057241\n",
      "R-squared score on the test set: 0.321396\n"
     ]
    }
   ],
   "source": [
    "def find_best_model_kfold(X, y, models, k=5):\n",
    "    best_model = None\n",
    "    best_rmse = float('inf')\n",
    "    \n",
    "    # KFold avec k folds (par défaut, 5)\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    for model in models:\n",
    "        fold_rmse = []\n",
    "        \n",
    "        # KFold splitting\n",
    "        for train_index, val_index in kf.split(X):\n",
    "            # Utilisation de .iloc pour indexer correctement le DataFrame\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "            fold_rmse.append(rmse)\n",
    "        \n",
    "        # Moyenne des RMSE sur les k folds\n",
    "        mean_rmse = np.mean(fold_rmse)\n",
    "        print(f\"Model: {model}, Mean RMSE across {k} folds: {mean_rmse}\")\n",
    "        \n",
    "        if mean_rmse < best_rmse:\n",
    "            best_rmse = mean_rmse\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Modèles linéaires à tester\n",
    "models = [LinearRegression(), Lasso(), Ridge(), ElasticNet(), PoissonRegressor()]\n",
    "\n",
    "# Trouver le meilleur modèle avec KFold\n",
    "best_model = find_best_model_kfold(X_learn, y_learn, models)\n",
    "\n",
    "print(\"\\nBest model:\", best_model)\n",
    "\n",
    "# Évaluation finale sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE on the test set: {rmse:.6f}\")\n",
    "print(f\"Mean Absolute Error on the test set: {mae:.6f}\")\n",
    "print(f\"R-squared score on the test set: {r2:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
